from langchain_core.messages import HumanMessage
from agent import agent_app

def run_chat_session():
    print("--- üè• CareNavigator Initialized (Type 'q' to quit) ---")
    
    # Initializ history with empty list 
    chat_history = []
    
    while True:
        user_input = input("\nYou: ")
        if user_input.lower() in ['q', 'quit']:
            break
            
        # 1. Add User Message to History
        user_msg = HumanMessage(content=user_input)
        chat_history.append(user_msg)
        
        # 2. Invoke the Agent with the FULL history
        # The agent will process, add its own replies to 'messages', and return the update
        output = agent_app.invoke({"messages": chat_history})
        
        # 3. Update our local history with the Agent's response(s)
        # LangGraph returns the *full* state or the updates. 
        # Since we used operator.add, output['messages'] usually contains the FULL list in this setup.
        # But to be safe and simple, let's grab the last message generated by the AI.
        
        last_response = output['messages'][-1]
        
        # Check if it was a "DATA_COLLECTED" internal signal (hidden from user)
        if "DATA_COLLECTED" in last_response.content:
            # If the agent signaled data collected, the Triage Node should have run immediately after.
            # So the REAL last message is the Triage summary.
            # We print that.
             print(f"Agent: {last_response.content.replace('DATA_COLLECTED', '')}")
        else:
            print(f"Agent: {last_response.content}")
            
        # Update history for next turn
        chat_history = output['messages']
        
        # 4. Check for Emergency Flag to break the loop
        if output.get("is_emergency"):
            break

if __name__ == "__main__":
    run_chat_session()